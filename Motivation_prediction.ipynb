{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ethioware/ML/blob/main/Motivation_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "R7h1ImL6ulgr"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler as ss\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "import copy\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Data Pre-processing**"
      ],
      "metadata": {
        "id": "gx-Q9rwsI37g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Z8T0yyKulgv"
      },
      "outputs": [],
      "source": [
        "#import the raw data (the first research)\n",
        "df = pd.read_csv(\"data.csv\")\n",
        "# dropping unnessacerry columns\n",
        "df = df.dropna(thresh=3) # drop the unwilling participants\n",
        "df = df.drop(['barriers_to_use','likely_to_use'], axis=1)\n",
        "#Binary numerical conversion\n",
        "df['lesson_utility'] = (df['lesson_utility'] == \"Yes\").astype(int)  # convert the Yes/No columns to 0/1\n",
        "df['use_edtech'] = (df['use_edtech'] == \"Yes\").astype(int)\n",
        "df['public'] = (df['public'] == \"Public (government)\").astype(int)\n",
        "df['n_smartphones'] = (df['n_smartphones'] == \"more than 3\").astype(int) # 1 if 3 and above\n",
        "df['Why_use'] = (df['Why_use'] == \"Improve my academic performance\").astype(int) # for grades\n",
        "df['app_demographic'] = (df['app_demographic'] == \"Social media\").astype(int) # for social media\n",
        "# filling N/A datapoints with the mean\n",
        "df = df.fillna(df.mean())\n",
        "df = df.round(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Data Processing**"
      ],
      "metadata": {
        "id": "cNlO5tLKZ4SZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Oversample**"
      ],
      "metadata": {
        "id": "LFv6agvbaBi3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the parameters\n",
        "# data = df.corr()\n",
        "# data = data.round(2)\n",
        "# fig, ax = plt.subplots(figsize=(12,8))\n",
        "# sns.heatmap(data,annot=True,ax=ax)"
      ],
      "metadata": {
        "id": "0HQbVlv6OrzK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uAMVTqzRulgv"
      },
      "outputs": [],
      "source": [
        "# oversample for more generalization and performance\n",
        "def scale(dataframe, oversample=False):\n",
        "    X = dataframe[dataframe.columns[1:]].values # all the columns after \"motivated\"\n",
        "    y = dataframe[dataframe.columns[0]].values # the \"motivation\" column\n",
        "    scaler = ss() # assign the variable scaler to StandardScaler library\n",
        "\n",
        "    if oversample:\n",
        "        ros = RandomOverSampler()\n",
        "        X, y = ros.fit_resample(X, y) # keep resampling until the \"lesser sample\" matches the larger one\n",
        "\n",
        "    X = scaler.fit_transform(X) # makes it scalable\n",
        "    data = np.hstack((X, np.reshape(y, (-1, 1)))) # new form or data stacked horizontally(hstack) with proper dimentions(reshape y to 2D)\n",
        "    return data, X, y"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train**"
      ],
      "metadata": {
        "id": "RPYmQv_DaF07"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lwfBzRBoulgw"
      },
      "outputs": [],
      "source": [
        "# split the dataset to train, validate, and test\n",
        "train, val, test = np.split(df.sample(frac=1), [int(0.6*len(df)), int(0.8*len(df))])\n",
        "# oversample the sectioned dataset\n",
        "train, X_train, y_train = scale(train, oversample = True) # inflate the traing datapoints\n",
        "val, X_val, y_val = scale(val, oversample=False) # don't tinker(False), we need to validate and test it with our training data only\n",
        "test, X_test, y_test = scale(test, oversample=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DVTPCE6Sulg1"
      },
      "outputs": [],
      "source": [
        " # visualize the accuracy during training\n",
        "\n",
        "def acc(data):\n",
        "    plt.plot(data.history['accuracy'], label = 'accuracy')\n",
        "    plt.plot(data.history['val_accuracy'], label = 'val_accuracy')\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    # Neural Network\n",
        "import tensorflow as tf\n",
        "\n",
        "nn_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(64, activation='relu', input_shape = (15,)), # initial layer with all 16 features as input\n",
        "    tf.keras.layers.Dropout(0.2), # to avoid overfitting and improve generalization\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(32, activation='relu'),# second layer\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid') # output layer with only one node\n",
        "])\n",
        "\n",
        "nn_model.compile(optimizer = tf.keras.optimizers.Adam(0.01), loss = 'mean_squared_error', metrics=['accuracy'])\n",
        "\n",
        "history = nn_model.fit(X_train, y_train, epochs= 100, batch_size=32, validation_split= 0.2, verbose='0')\n",
        "acc(history) # visualizing the above neural net training process\n",
        "print(cr(y_test, y_pred)) # a report telling us how our test and prediction compare in accuracy and other metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mU8RSWnlulg1",
        "outputId": "c1bc3cc4-8cf2-43c8-bb25-c25dca76c67c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.00      0.00      0.00         1\n",
            "         2.0       0.00      0.00      0.00         5\n",
            "         3.0       0.07      0.25      0.11         4\n",
            "         4.0       0.58      0.54      0.56        13\n",
            "         5.0       0.60      0.30      0.40        10\n",
            "\n",
            "    accuracy                           0.33        33\n",
            "   macro avg       0.25      0.22      0.21        33\n",
            "weighted avg       0.42      0.33      0.35        33\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "    # Support Vector Machines\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report as cr\n",
        "\n",
        "svm_model = SVC()\n",
        "svm_model = svm_model.fit(X_train, y_train) # train our model using (fitting) Support Vector Machines algorithm\n",
        "\n",
        "y_pred = svm_model.predict(X_test) # assign our tested prediction to a variable \"y_pred\"\n",
        "print(cr(y_test, y_pred)) # a report telling us how our test and prediction compare in accuracy and other metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJYWeE5mulgw"
      },
      "source": [
        "### K-Nearest Neighbors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1K5oe9G1ulgy",
        "outputId": "c81cc813-7d56-4535-b023-8d0223a2da31",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.00      0.00      0.00         1\n",
            "         2.0       0.00      0.00      0.00         0\n",
            "         3.0       0.60      0.25      0.35        12\n",
            "         4.0       0.80      0.40      0.53        10\n",
            "         5.0       0.67      0.40      0.50        10\n",
            "\n",
            "    accuracy                           0.33        33\n",
            "   macro avg       0.41      0.21      0.28        33\n",
            "weighted avg       0.66      0.33      0.44        33\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "# use various algoritms and keep the most accurate one with manupilating its parameters to get the best performance\n",
        "\n",
        "    # K-nearest neighbors\n",
        "from sklearn.neighbors import KNeighborsClassifier as knn\n",
        "from sklearn.metrics import classification_report as cr\n",
        "\n",
        "knn_model = knn(n_neighbors= 8) # use n_neighbors features (used all the feature vectors)\n",
        "knn_model.fit(X_train, y_train) # train our model using (fitting) Knn algorithm\n",
        "\n",
        "y_pred = knn_model.predict(X_test) # assign our tested prediction to a variable \"y_pred\"\n",
        "print(cr(y_test, y_pred)) # a report telling us how our test and prediction compare in accuracy and other metrics\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXP2Spigulgz"
      },
      "source": [
        "## Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yc9T8dUIulgz",
        "outputId": "9fbf98de-142b-4e92-ef5d-99c592b7f631",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.00      0.00      0.00         1\n",
            "         2.0       0.00      0.00      0.00         0\n",
            "         3.0       0.64      0.75      0.69        12\n",
            "         4.0       0.43      0.30      0.35        10\n",
            "         5.0       0.60      0.30      0.40        10\n",
            "\n",
            "    accuracy                           0.45        33\n",
            "   macro avg       0.33      0.27      0.29        33\n",
            "weighted avg       0.55      0.45      0.48        33\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "\n",
        "    # Naive Bayes\n",
        "from sklearn.naive_bayes import GaussianNB as nb\n",
        "from sklearn.metrics import classification_report as cr\n",
        "\n",
        "nb_model = nb()\n",
        "nb_model = nb_model.fit(X_train, y_train) # train our model using (fitting) Naive Bayes algorithm\n",
        "\n",
        "y_pred = nb_model.predict(X_test) # assign our tested prediction to a variable \"y_pred\"\n",
        "print(cr(y_test, y_pred)) # a report telling us how our test and prediction compare in accuracy and other metrics\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuVhMBVsulg0"
      },
      "source": [
        "### Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LecDuxiRulg0",
        "outputId": "09c915c9-98f4-4926-af79-b2a65639b2c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.00      0.00      0.00         1\n",
            "         2.0       0.00      0.00      0.00         0\n",
            "         3.0       0.54      0.58      0.56        12\n",
            "         4.0       0.50      0.10      0.17        10\n",
            "         5.0       0.43      0.30      0.35        10\n",
            "\n",
            "    accuracy                           0.33        33\n",
            "   macro avg       0.29      0.20      0.22        33\n",
            "weighted avg       0.48      0.33      0.36        33\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "   # Logistic Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report as cr\n",
        "\n",
        "lg_model = LogisticRegression()\n",
        "lg_model = lg_model.fit(X_train, y_train) # train our model using (fitting) Logistic Regression algorithm\n",
        "\n",
        "y_pred = lg_model.predict(X_test) # assign our tested prediction to a variable \"y_pred\"\n",
        "print(cr(y_test, y_pred)) # a report telling us how our test and prediction compare in accuracy and other metrics\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUl237e7ulg0"
      },
      "source": [
        "### Support Vector Machines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSTE94kXulg1"
      },
      "source": [
        "### Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-uWDA6Culg1"
      },
      "source": [
        "### Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hzSu1IM5ulg2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05440071-9bfc-4b9b-fea9-7547ae5c7f30"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.8790271081167174"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "    # Linear Regression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "lr_model = LinearRegression()\n",
        "lr_model = lr_model.fit(X_train, y_train) # train our model using (fitting) Linear Regression algorithm\n",
        "\n",
        "lr_model.score(X_test, y_test) # accuracy of our model\n",
        "#acc(lr_model) # visualizing the above LinearRegression training process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WR2LGdbMulg2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ethioware/ML/blob/main/Motivation_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "R7h1ImL6ulgr"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler as ss\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "import copy\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8-MSiCtKulgu"
      },
      "outputs": [],
      "source": [
        "#import the raw data (the first research)\n",
        "\n",
        " # include all the parameters\n",
        "df = pd.read_csv(\"Mo.csv\")\n",
        "#df[\"yes/no col name\"] = (df[\"yes/no col name\"] == \"yes\").astype(int) # for our second dataset\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Z8T0yyKulgv"
      },
      "outputs": [],
      "source": [
        "# visualize the data and remove(drop) the ones with no pattern(!increase, decrease...)\n",
        "for label in df.columns [1:]: # use all the columns after the first one(we need the first column as a y vector/outcome)\n",
        "    plt.scatter(df[label], df[\"motivated\"]) # use each column after the first as x axis, but keep using \"motivated\" column as y axis when plotting the scatter plot\n",
        "    plt.title(\"Academic Motivation Level\")\n",
        "    plt.ylabel(\"Motivation Level\")\n",
        "    plt.xlabel(lable) # keep the x-axis labled as the data columns\n",
        "    plt.legend() # include a legend for each plot\n",
        "    plt.show() # draw it\n",
        "\n",
        "# Drop the visually uncorelated ones\n",
        "df = df.drop([\"\",\"\"], axis=1) # drop the selected columns(axis=1)\n",
        "df.head() # check the above operation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uAMVTqzRulgv"
      },
      "outputs": [],
      "source": [
        "# oversample for more generalization and performance\n",
        "def scale(dataframe, oversample=False):\n",
        "    X = dataframe[dataframe.columns[1:]].values # all the columns after \"motivated\"\n",
        "    y = dataframe[dataframe.columns[1]].values # the \"motivated\" column\n",
        "    scaler = ss() # assign the variable scaler to StandardScaler library\n",
        "\n",
        "    if oversample:\n",
        "        ros = RandomOverSampler()\n",
        "        X, y = ros.fit_resample(X, y) # keep resampling until the \"lesser sample\" matches the larger one\n",
        "\n",
        "    X = scaler.fit_transform(X) # makes it scalable\n",
        "    data = np.hstack((X, np.reshape(y, (-1, 1)))) # new form or data stacked horizontally(hstack) with proper dimentions(reshape y to 2D)\n",
        "    return data, X, y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lwfBzRBoulgw",
        "outputId": "0ae7715f-a305-40ff-d4cc-e3f16fdf7412"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'np' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-b82476df1f76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# split the dataset to train, validate, and test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrac\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.70\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.15\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.15\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# oversample the sectioned dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moversample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# inflate the traing datapoints\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moversample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# don't tinker(False), we need to validate and test it with our training data only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ],
      "source": [
        "# split the dataset to train, validate, and test\n",
        "train, val, test = np.split(df.sample(frac=1), [int(0.70*len(df))], [int(0.15*len(df))], [int(0.15*len(df))])\n",
        "# oversample the sectioned dataset\n",
        "train, X_train, y_train = scale(train, oversample=True) # inflate the traing datapoints\n",
        "val, X_val, y_val = scale(val, oversample=False) # don't tinker(False), we need to validate and test it with our training data only\n",
        "test, X_test, y_test = scale(test, oversample=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJYWeE5mulgw"
      },
      "source": [
        "### K-Nearest Neighbors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1K5oe9G1ulgy",
        "outputId": "765d40ed-9004-4bbf-b0a4-84e65b328310"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'sklearn'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-0d0fe42b3b26>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# K-nearest neighbors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneighbors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mknn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclassification_report\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
          ]
        }
      ],
      "source": [
        "# use various algoritms and keep the most accurate one with manupilating its parameters to get the best performance\n",
        "\n",
        "    # K-nearest neighbors\n",
        "from sklearn.neighbors import KNeighborsClassifier as knn\n",
        "from sklearn.metrics import classification_report as cr\n",
        "\n",
        "knn_model = knn(n_neighbors= 19) # use n_neighbors features (used all the feature vectors)\n",
        "knn_model.fit(X_train, y_train) # train our model using (fitting) Knn algorithm\n",
        "\n",
        "y_pred = knn_model.pridict(X_test) # assign our tested prediction to a variable \"y_pred\"\n",
        "print(cr(y_test, y_pred)) # a report telling us how our test and prediction compare in accuracy and other metrics\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXP2Spigulgz"
      },
      "source": [
        "## Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yc9T8dUIulgz",
        "outputId": "03222fc3-ce5c-4163-e6c1-bf34fea2836c"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'sklearn'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-c5d1dc99a16b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# Naive Bayes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnaive_bayes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGaussianNB\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclassification_report\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
          ]
        }
      ],
      "source": [
        "\n",
        "    # Naive Bayes\n",
        "from sklearn.naive_bayes import GaussianNB as nb\n",
        "from sklearn.metrics import classification_report as cr\n",
        "\n",
        "nb_model = nb\n",
        "nb_model = nb_model.fit(X_train, y_train) # train our model using (fitting) Naive Bayes algorithm\n",
        "\n",
        "y_pred = nb_model.pridict(X_test) # assign our tested prediction to a variable \"y_pred\"\n",
        "print(cr(y_test, y_pred)) # a report telling us how our test and prediction compare in accuracy and other metrics\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuVhMBVsulg0"
      },
      "source": [
        "### Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LecDuxiRulg0",
        "outputId": "5fb6c2b1-a809-40f6-9af5-afa0c352829b"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'sklearn'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-1dba2548ecdd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Logistic Regression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclassification_report\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlg_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
          ]
        }
      ],
      "source": [
        "   # Logistic Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report as cr\n",
        "\n",
        "lg_model = LogisticRegression()\n",
        "lg_model = lg_model.fit(X_train, y_train) # train our model using (fitting) Logistic Regression algorithm\n",
        "\n",
        "y_pred = svm_model.pridict(X_test) # assign our tested prediction to a variable \"y_pred\"\n",
        "print(cr(y_test, y_pred)) # a report telling us how our test and prediction compare in accuracy and other metrics\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUl237e7ulg0"
      },
      "source": [
        "### Support Vector Machines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mU8RSWnlulg1",
        "outputId": "df661cde-5e2e-4519-ab7b-e7cac82d86c1"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'sklearn'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-bc8e78dfc6d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Support Vector Machines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msvm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclassification_report\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msvm_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
          ]
        }
      ],
      "source": [
        "    # Support Vector Machines\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report as cr\n",
        "\n",
        "svm_model = SVC()\n",
        "svm_model = svm_model.fit(X_train, y_train) # train our model using (fitting) Support Vector Machines algorithm\n",
        "\n",
        "y_pred = svm_model.pridict(X_test) # assign our tested prediction to a variable \"y_pred\"\n",
        "print(cr(y_test, y_pred)) # a report telling us how our test and prediction compare in accuracy and other metrics\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSTE94kXulg1"
      },
      "source": [
        "### Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DVTPCE6Sulg1",
        "outputId": "5eca47d8-d3b5-4359-a155-7e089c810af6"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-10-0e0bd6e0361a>, line 16)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-10-0e0bd6e0361a>\"\u001b[0;36m, line \u001b[0;32m16\u001b[0m\n\u001b[0;31m    tf.keras.layers.Dense(64, activation='relu'), input_shape = (19,)), # initial layer with all 19 features as input\u001b[0m\n\u001b[0m                                                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        " # visualize the accuracy during training\n",
        "\n",
        "def acc(data):\n",
        "    plt.plot(history.data['accuracy'], label = 'accuracy')\n",
        "    plt.plot(history.data['val_accuracy'], label = 'val_accuracy')\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    # Neural Network\n",
        "import tensorflow as tf\n",
        "\n",
        "nn_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(64, activation='relu'), input_shape = (19,)), # initial layer with all 19 features as input\n",
        "    tf.keras.layers.Dropout(0.2), # to avoid overfitting and improve generalization\n",
        "    tf.keras.layers.Dense(64, activation='relu'), # second layer\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(1, activation='relu') # output layer with only one node\n",
        "])\n",
        "\n",
        "nn_model.compile(optimizer = tf.keras.optimizers, Adam(0.001), loss = 'mean_squared_error', matrics['accuracy'])\n",
        "\n",
        "history = nn_model.fit(X_train, y_train, epochs=100, batch_size = 64, validation_split  = 0.2, verboss=0)\n",
        "acc(history) # visualizing the above neural net training process\n",
        "print(cr(y_test, y_pred)) # a report telling us how our test and prediction compare in accuracy and other metrics\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-uWDA6Culg1"
      },
      "source": [
        "### Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hzSu1IM5ulg2"
      },
      "outputs": [],
      "source": [
        "    # Linear Regression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "lr_model = LinearRegression()\n",
        "lr_model = lr_model.fit(X_train, y_train) # train our model using (fitting) Linear Regression algorithm\n",
        "\n",
        "lr_model.score(X_test, y_test) # accuracy of our model\n",
        "acc(lr_model) # visualizing the above LinearRegression training process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WR2LGdbMulg2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}